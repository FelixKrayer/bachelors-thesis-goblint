% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}
  Abstract interpretation is a fascinating theory. When its principles are used in static analysis, one can prove certain properties of computer programs. Through the sound abstractions of abstract interpretation, it is ensured that any proven property holds true for all possible executions of a program. The most interesting parts of this application are the different ways by which states of a program can be abstracted and how these abstractions can be combined to gain various kinds of information about a program.\\
  The \gob\ analyzer is a project that applies the principles of abstract interpretation to create a static analyzer~\parencite{goblintHome}.\\
  This analyzer is specialized in, but not limited to finding concurrency bugs. These are some properties it aims to check:
  \begin{itemize}
    \item Race Detection: Checking that accesses to shared memory never happen simultaneously.
    \item Assertions and Dead Code: Checking whether specific logical expressions are definitely true at given points within the program. 
    \item Integer Overflows: Verifying that no integer overflows occur in the program.
  \end{itemize}
  To gain information about a program, \gob\ performs various kinds of analyses on the source code. These analyses abstract states of the program in different ways. They are also able to communicate with each other to profit from the information gained by other analyses. Because it is easily expandable, \gob\ is an interesting framework to try out new approaches in static analysis.\\
  \\
  The analyzer is highly configurable. This allows the user to fine-tune the degree of precision they wish. However, it has to be considered that a higher degree of precision usually results in a higher computation time.\\
  With such a configuration option the user can specify a variant of context-sensitivity for each analysis. It is possible to set an analysis to be performed fully context-sensitively, context-insensitively or partially context-sensitively. Context-sensitivity describes the way, in which entry states of functions are differentiated: When full context-sensitivity is chosen, a function is analyzed separately for each entry state, while with context-insensitivity it is only analyzed one time with a summary of all entry states. Different variants of partial context-sensitivity allow for grouping the entry states in certain ways, where a function is then analyzed once per group with a summary of that group.

  \begin{figure}[!ht]
    \centering
    \begin{subfigure}{0.35\textwidth}
      \centering
      \lstinputlisting[escapechar=|, language=C]{../code/01-example_intro.c}
    \end{subfigure}
    \caption[C code sample with multiple function calls.]{C code sample with multiple function calls to illustrate the precision loss of partial context-sensitivity.}
    \label{fig:exampleIntro}
  \end{figure}

  \noindent Consider the program in \autoref{fig:exampleIntro}. Assume this program is analyzed with the goal to find out which values the program variables can have during program execution. For this, an analysis is used that tracks a set of integers for each variable, i.e., it computes an abstract state describing the possible values of all variables for each program point. The abstract state (in this case a set of values per variable) for a program point is computed by applying the effect of an action, e.g., an instruction, to the state before this action. Most actions have effects that are easily computable, however, function calls are of a more complicated nature, as they can be called from multiple places in a program.\\
  The program in \autoref{fig:exampleIntro} contains two calls to \texttt{foo()}, one in \autoref{code:call1} and the other in \autoref{code:call2}. If this program is analyzed context-sensitively, the function is analyzed twice: Once with an abstract entry state describing that "\texttt{glob} = 1" and once with a state describing "\texttt{glob} = 2". However, if the analysis is performed context-insensitively, both of these two entry states are joined into one abstract state which is used to analyze the function only once. This joined abstract state then has to describe all the concrete states, where "\texttt{glob} = 1 or \texttt{glob} = 2", which is less precise than either of the individual states from before.\\
  When the state after a function call is computed, the information about \texttt{glob} is taken from the state returned from the callee. This is because \texttt{glob} is a global variable and thus its value can be changed in function calls.\\
  However, consider the case, where \texttt{glob} is not changed during the call to \texttt{foo()}. Then the information about \texttt{glob} in the callee return state is the same as in the entry state for that specific call. This means, that in the case of the context-insensitive analysis, the less precise information "\texttt{glob} = 1 or \texttt{glob} = 2" from the joined entry state is used for \texttt{glob} after both calls. This is a loss of precision, considering that the value of \texttt{glob} was not altered in the call, and thus, for both states after a call to \texttt{foo()} it would be sound to keep the information about \texttt{glob} from before that call.\\
  \\
  We think this precision loss is avoidable in many cases, where a piece of less precise information is taken from the callee state, even though that piece of information was not changed during the call. Thus, in this thesis, we explore a way to reduce this kind of precision loss of partial contexts in abstract interpretation for certain analyses. 

  \paragraph{Related work}\mbox{}\\
  In the following we discuss some approaches other researchers proposed to improve the precision of (partial) context-sensitivity. The vast majority of these aim to refine context-insensitive analyses with partial or selective context-sensitivity applied to certain elements of a program:\\
  There are multiple approaches proposing variants of "selective context-sensitivity". In general, selective context-sensitive analyses aim to choose a suitable variant of (partial) context-sensitivity depending on the procedure to be analyzed.\\
  A variant of selective context-sensitivity is proposed by Smaragdakis et al.~\parencite{smaragdakis2014introspective}. They introduce an "introspective context-sensitivity" approach for Java programs, where first a context-insensitive analysis is performed. The results of which are used to select program elements that are refined through a context-sensitive analysis of specific methods. In their work, they give different heuristics by which the program elements to be refined are chosen. It is worth mentioning that they acknowledge an often-reported phenomenon: Either context-sensitivity scales rather well in terms of computation time, i.e., it is almost as fast as context-insensitivity, or, in other cases, it scales very badly and takes magnitudes longer. We found a similar phenomenon in our benchmarks.\\
  Li et al.(2018)~\parencite{li2018scalability} give a related approach: they also first perform a context-insensitive pre-analysis and use the results to tune context-sensitivity per method. However, instead of choosing between context-sensitivity and -insensitivity, they select from multiple variants of context-sensitivity. These variants are comparable to certain fixed variants of partial context-sensitivity in our terminology.\\
  Another approach is given by Li et al.(2020)~\parencite{li2020principled}, that again is concerned with deciding to which methods context-sensitivity should be applied and which variant. However, instead of relying on heuristics like Smaragdakis et al.~\parencite{smaragdakis2014introspective} they identify program patterns and use these as a basis for the selection. For this, they investigate and identify sources of precision loss caused by context-insensitivity as we do in this thesis. While our focus lies on identifying and combatting the precision loss that occurs with parts of the program state that are not altered during a call, they concentrate on the way precision is lost for parts of the program state that are changed in a call.\\
  Lu and Xue~\parencite{lu2019precision} give a different approach to selective context-sensitivity: Instead of focussing on choosing whether context-sensitivity or which variant of it should be applied to a method, they tune the context per method on a variable-grained level. For this, they use the concept of "partial context-sensitivity" which we also use in our thesis. However, while we generally fix the variant of partial context-sensitivity for the analysis overall or set it manually, they automatically choose different variants for individual methods. In particular, they use insights from context-free-language reachability at the level of variables to choose which variables should be in the context of a certain method, i.e., with respect to which variables the method should be analyzed context-sensitively. Similar to the publication by Li et al. (2020)~\parencite{li2020principled}, they identify and discuss sources of precision loss, but again with the focus on parts of the program state that are changed in a call. The precision loss we address in this thesis occurs in parts of the state that are not changed in a call.\\
  Lastly, Thakur and Nandivada~\parencite{thakur2019compare} propose an interesting approach that makes use of the observation that not all methods have an impact on the caller state. First, the program is pre-analyzed flow-insensitively to identify which parts of the caller state are needed in the callee. The results of this are then used to perform a flow- and context-sensitive analysis on the program, where the analysis of methods that do not impact the caller state is deferred to a post-analysis in order to gain efficiency. In this thesis, we make use of a similar observation, that some parts of the caller state are not impacted by the call. Thakur and Nandivada~\parencite{thakur2019compare} use this insight to compare the contexts for method calls and defer the analysis of certain methods. In contrast to that, we use this observation to identify and keep information from the caller state that is definitely not changed during the call.\\
  Even though the approaches given above are used to analyze the Java programming language, their concepts can be analogously applied to the C language we analyze with \gob\ in this thesis. However, we mention this approach by Oh et al.~\parencite{oh2014selective}, who like us apply their concepts to C programs: They use a context-insensitive pre-analysis to identify which functions are likely to benefit from being analyzed context-sensitively.\\
  All these publications propose and discuss different ways to improve context-insensitive analyses in terms of precision. They use various insights and observations to find a suitable variant of context-sensitivity for different program elements or suitable contexts for different methods, functions or procedures. However, the approach we present in this thesis is not concerned with choosing from variants of context-sensitivity or altering the way contexts are chosen. Instead, it identifies parts of the caller state that are definitely not altered during the call and keeps them from the state before the call. Interestingly, since our concept is concerned with an entirely different aspect than the other approaches we discussed above, it can theoretically be combined with any one of them to improve its precision without interference.

  \paragraph{Structure}\mbox{}\\
  This thesis is structured as follows: First, we discuss the basics of static analysis in \autoref{chapter:background}. For this, we introduce constraint systems and how these are used to gain information about the program statically. This is accompanied by the example of a value-of-variables analysis acting on a toy language we use to exemplify applications of static analyses in this thesis. We explain how interprocedural analysis is handled and introduce (partial) context-sensitivity. Here a source of the precision loss is identified. In the following two chapters, we take a closer look at two kinds of analyses that suffer from this loss of precision in different ways. For each kind we propose an approach to reduce the precision loss: In \autoref{chapter:precisionLossVariableAnalyses} we aim to improve analyses that track information about variables and in \autoref{chapter:precisionLossThreadAnalyses} we give an approach to reduce the precision loss of a thread-related analysis. Both approaches are first discussed conceptually, after which we present the challenges and results of implementing them in the \gob\ analyzer. To give an evaluation of the proposed approaches, a benchmark of the implementation is performed and inspected in \autoref{chapter:evaluation}. Our conclusions are presented in \autoref{chapter:conclusions}.
