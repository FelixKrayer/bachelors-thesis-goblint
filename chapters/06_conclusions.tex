% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusions}\label{chapter:conclusions}
  In this thesis we introduced static analysis with systems of constraints. After expanding the approach to interprocedural analysis with various kinds of context-sensitivity, we identified a source of precision loss that can occur with context-insensitive and partially context-sensitive analyses. In the following two chapters we focused on two different kinds of analyses, where this loss of precision occurs and proposed an improvement that reduces the precision lost for each kind. We implemented both of our proposed approaches in the \gob\ analyzer. Afterwards we tested and benchmarked our implementation.\\
  \\
  The following conclusions originate mostly from the results of the benchmarks we performed with the \texttt{base} analysis of \gob. This analysis is based on the values-of-variables analysis and expands on it. Thus, we suspect our conclusions to hold for this type of analysis in general.\\
  In contrast to our expectation, the precision loss of performing the \texttt{base} analysis context-insensitively instead of context-sensitively does not lead to a great loss of precision in general.\\
  Additionally, the benefit of a faster computation time through context-insensitivity is also smaller than expected for most programs. There are however certain programs, where a context-sensitive \texttt{base} analysis struggles as it terminates with a timeout or stack overflow, while a context-insensitive \texttt{base} analysis terminates much quicker without an error. A shallow investigation of this phenomenon showed, that a large portion of the programs for which these errors occurred are programs with recursive functions.\\
  Adding the taint analysis we proposed in this thesis only provided a limited improvement in precision to the context-insensitive case. However, as mentioned above only a small portion of precision was lost through context-insensitivity. This limits the improvement, which the taint analysis can provide as its addition cannot make a context-insensitive analysis more precise than a context-sensitive one. Comparing the amount of precision lost through context-insensitivity with the amount of precision recovered by the taint analysis makes the benefit of the taint analysis much more noticeable.\\
  For computation time we note that a context-insensitive \texttt{base} analysis improved with the taint analysis takes about as long as a context-sensitive \texttt{base} analysis with some variance, provided neither of them terminates with an error. However, just like the context-sensitive analysis by itself, the improved analysis terminates with an error in much fewer cases than the context-sensitive analysis.\\
  The benchmark for our changes to the thread ID analysis was extremely limited, and thus we cannot give more than a first impression based on its results: We did not record any precision loss. Thus, we suspect that for most real-world programs performing the thread ID analysis partially context-sensitively, as introduced it in this thesis, does not result in a large precision loss if any. We cannot comment on the performance of the thread create analysis. The reason for this is, that this analysis can only reduce existing precision loss, but we recorded none in the benchmark. Further benchmarks are necessary for a more expressive conclusion on this kind of analysis.\\
  \\
  We would like to perform further benchmarks on the thread ID and thread create analysis. A run of the SV-Benchmarks' tasks with the \texttt{no-data-race} property is a suitable next step.\\
  Furthermore, we want to inspect the benchmark results for the \texttt{base} analysis more closely. We hope to find some sort of characterization of programs, where the taint analysis provided an improvement.\\
  Lastly we note that similar approaches to the ones we proposed in the taint and thread create analysis can be applied to other kinds of analyses. In general, if it can be identified that some part of a state was not altered during a procedure call, that part can be kept from the caller state and does not have to be overwritten by potentially less precise information from the callee state. We would like to experiment with applying this principle to other analyses in future work.\\

%\begin{itemize}
%  \item \textbf{Summary:}
%  \item Source of Precison loss identified
%  \item Two ideas for reducing the precision loss for two types of analyses
%  \item implemented in \gob\ and tested to prove viability
%  \item benchmarked to check if a noticeable improvement is achieved
%  \item \textbf{Conclusions:}
%  \item -> in general insens not that costly (precision) but also not that much faster.
%  \item -> however insens produces less errors (Timeout/Stack overflow)
%  \item -> taint in general not that much benefit, but it has its uses (but not much faster compared to sens)
%  \item recursive is problematic with sens (error often), insens finds unknown much faster.
%  \item \textbf{Future Work}
%  \item general approach (identify partial information of a state that has not been changed by call and keep that from the caller state instead of overwriting it with less precis callee info)
%  \item more extensive benchmark for thread Create
%  \item inspect types of programs (e.g. recursive)
%  \item can be combined with any of related work approaches without any issues
%  \item autotuner somehow???
%\end{itemize}
