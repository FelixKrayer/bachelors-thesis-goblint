% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Combatting Precision Loss}\label{chapter:mainContributions}
  In this chapter we will describe our approach to reduce the precision loss described in \autoref{section:precisionLoss}. We will first use the syntax for flow sensitive analyses from \autoref{chapter:background} to formally define the idea. After that we explain the concrete implementation of the approach into the \gob analyzer.
  \section{Formal description}
    \subsection{Taint analysis}
      The basic idea to combat the precison loss is to track for each procedure which variables have been written or have possibly been altered in some other way. This information is then used in the values-of-variables analysis when combining the abstract state from the caller with the abstract return state given by the callee at the end of the procedure.\\
      In the following we will call a variable that has been written or altered in the current procedure context "tainted". Therefore, we introduce a new taint analysis tracking which variables have been tainted within the context of the current procedure. It is worth mentioning that our notion of taintedness is related but different from other uses of this concept.\\
      \\
      Let us now formulate the syntax for our taint analysis:
      Since we want to find a collection of tainted variables per program point, a suitable domain for this analysis is the powerset of the set of variables $X$ ordered by the subset relation:
      \[\mathbb{D}_\textsf{t} = 2^X \text{ with } \sqsupseteq_\textsf{t} = \supseteq\]
      From that follows that we seek to compute a mapping from program points to sets of variables i.e. $\eta_\textsf{t}: N \rightarrow \mathbb{D}_\textsf{t}$. To interpret this with the goal of our taint analysis in mind, we note that $\eta_\textsf{t} [n] = T$ will denote that $T$ is the set of possibly tainted variables at program point $[n]$. Expressed differently this means that for any variable $x \in T$ we cannot exclude that this variable was altered between the start of the procedure $[n]$ is in up until the program pint $[n]$.\\
      It remains to define $\textsf{init}^{\#}$, $\textsf{enter}^{\#}$ and $\textsf{combine}^{\#}$ as well as the abstract effects of actions $[\![  A ]\!]^{\#}$. Recall that the notion of a "tainted" variable is defined in relation to the current procedure. This means we want to start fresh whenever we enter a procedure and start without any variable being initially tainted. Since the same holds for the initial state we have 
      \[\textsf{enter}^{\#}\ T = \textsf{init}^{\#} = \emptyset\]
      When combining the caller state with the returned callee state, we note that anything that we need to keep the tainted set from before the call, as a tainted variable can get never get "untainted" again, no matter what the procedure does. In addition to that we will add the set returned by the callee, as anything tainted in the call needs to be considered tainted in the caller as well. This is because we want to know which variables have been altered in a procedure call, no matter if the tainting happened within the procedure itself or within a procedure called by the procedure. This leaves us with the following equation for the $\textsf{combine}^{\#}$ function:
      \[ \textsf{combine}^{\#}\ (T_\textsf{cr}, T_\textsf{ce}) = T_\textsf{cr} \cup (T_\textsf{ce} \backslash Locals_\textsf{ce}) \]
      Note that we removed the callee local variables $Locals_\textsf{ce}$ because these are not accessible by the caller and all of its callers anyway, so it is not useful to keep track of them.
      It is also worth pointing out that the function $\textsf{enter}^{\#} T$ is always equal to the empty set irregardles of its argument $T$. Therefore it computes the same function context for each call of a certain procedure making our taint analysis inherently context insensitive.
      
      // \textbf{WIP:}\\
      \\
      Each edge $e = (u, A, v)$ introduces the constraint $\eta_\textsf{t}\ [v] \sqsupseteq [\![  A ]\!]^{\#}  (\eta_\textsf{t}\ [u]) $\\
      \[ [\![ x = y; ]\!] ^{\#}\ T =  T \cup \{x\} \]


    \subsection{Improving the values-of-variables analysis}
    //\textbf{WIP:}\\
      \begin{align*}
        \textsf{combine}^{\#}\ M_\textsf{cr}\ M_\textsf{ce} = & \text{let } M'_\textsf{cr} = M_\textsf{cr}|_{Locals_\textsf{cr} \cup (Globals \cap T_\textsf{ce})} \text{ in}\\
        & \text{let } M'_\textsf{ce} = M_\textsf{ce}|_{Globals \cap T_\textsf{ce}}\text{ in} \\
        & M'_\textsf{cr} \oplus M'_\textsf{ce}
      \end{align*}

  \section{Implementation}
  //\textbf{WIP:}\\
    The \gob analyzer provides a framework for static analyses.\\ 
    // signature from analysis.ml\\
    \\
    As a domain we chose not a set of variables, but a set of lvalues, where an lvalue can be any left hand side of an assignment instruction. Examples of lvalues are: the variable $x$, the memory location $*xptr$ pointed to by the pointer $xptr$, the third place $a[3]$ in an array $a$, the member $frac.n$ of a struct $frac$ and many more. This allows us to find that only a part of an array or structure is tainted, so we can keep most of these and only update the tainted lvalues.\\
    //TOP necessary\\
    However analyzing the full language C instead of our toy language, it is necessary to take care of further challenges like pointers and library or unknown functions.\\
    // \gob provides \textsf{MayPointTo}()\\
    // \gob provides library descriptors -> unknown = top\\






